{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Conv2D, Flatten, Conv2DTranspose, Reshape, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras import objectives\n",
    "from keras.datasets import mnist\n",
    "from keras.activations import softmax\n",
    "from keras.objectives import binary_crossentropy as bce\n",
    "from keras.objectives import mean_squared_error as mse\n",
    "\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(logits_y):\n",
    "    U = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "    y = logits_y - K.log(-K.log(U + 1e-20) + 1e-20) # logits + gumbel noise\n",
    "    y = softmax(K.reshape(y, (-1, N, M)) / tau)\n",
    "#     y = softmax(K.reshape(y, (N, M)) / tau,axis=-1)\n",
    "    y = K.reshape(y, (-1, N*M))\n",
    "    return y\n",
    "\n",
    "\n",
    "# def gumbel_loss(x, x_hat):\n",
    "#     q_y = K.reshape(logits_y, (-1, N, M))\n",
    "#     q_y = softmax(q_y)\n",
    "#     log_q_y = K.log(q_y + 1e-20)\n",
    "#     kl_tmp = q_y * (log_q_y - K.log(1.0/M))\n",
    "#     KL = K.sum(kl_tmp, axis=(1, 2))\n",
    "# #     elbo = data_dim * bce(x, x_hat) - KL \n",
    "#     elbo = DATA_DIM * bce(x, x_hat) - KL\n",
    "#     return elbo\n",
    "\n",
    "# def gumbel_loss(x, x_hat):\n",
    "#     print(K.shape(logits_y))\n",
    "#     q_y = K.reshape(logits_y, (-1, N, M))\n",
    "#     print(K.shape(logits_y))\n",
    "#     q_y = softmax(q_y)\n",
    "#     log_q_y = K.log(q_y + 1e-20)\n",
    "#     kl_tmp = q_y * (log_q_y - K.log(1.0/M))\n",
    "#     KL = K.sum(kl_tmp, axis=(1, 2))\n",
    "# #     elbo = data_dim * bce(x, x_hat) - KL \n",
    "#     elbo = DATA_DIM * bce(x, x_hat) - KL\n",
    "#     return elbo\n",
    "\n",
    "def gumbel_loss(x, x_hat):\n",
    "    q_y = K.reshape(logits_y, (-1, N, M))\n",
    "    q_y = softmax(q_y)\n",
    "    log_q_y = K.log(q_y + 1e-20)\n",
    "    kl_tmp = q_y * (log_q_y - K.log(1.0/M))\n",
    "    KL = K.sum(kl_tmp, axis=(1, 2))\n",
    "    x = K.reshape(x, (1,-1))\n",
    "    x_hat = K.reshape(x_hat, (1,-1))\n",
    "#     elbo = DATA_DIM * bce(x, x_hat) - KL\n",
    "    elbo = DATA_DIM * mse(x, x_hat) - KL\n",
    "    return elbo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "DATA_DIM = 784\n",
    "M = 15\n",
    "N = 10\n",
    "nb_epoch = 30 #100\n",
    "epsilon_std = 0.01\n",
    "\n",
    "anneal_rate = 0.0003\n",
    "min_temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "logits_y (Dense)             (None, 150)               38550     \n",
      "_________________________________________________________________\n",
      "lambda_17 (Lambda)           (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 784)               572432    \n",
      "=================================================================\n",
      "Total params: 1,144,230\n",
      "Trainable params: 1,144,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tau = K.variable(5.0, name=\"temperature\")\n",
    "# tau = K.variable(2.5, name=\"temperature\")\n",
    "\n",
    "# x = Input(batch_shape=(batch_size, DATA_DIM))\n",
    "x = Input(shape=( 784, ))\n",
    "h = Dense(256, activation='relu')(Dense(512, activation='relu')(x))\n",
    "logits_y = Dense(M*N, activation='relu', name=\"logits_y\")(h)\n",
    "\n",
    "# z = Lambda(sampling, output_shape=(M*N,))(logits_y)\n",
    "\n",
    "z_lay = Lambda(sampling, output_shape=(M*N,))\n",
    "z = z_lay(logits_y)\n",
    "z_ = Activation(None)(z)\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, activation='relu', input_shape=(N*M, )))\n",
    "generator.add(Dense(512, activation='relu'))\n",
    "generator.add(Dense(DATA_DIM, activation='sigmoid'))\n",
    "x_hat = generator(z)\n",
    "\n",
    "# x_hat = Dense(data_dim, activation='softmax')(Dense(512, activation='relu')(Dense(256, activation='relu')(z)))\n",
    "\n",
    "vae = Model(x, x_hat)\n",
    "vae_test = Model(x, [x_hat, logits_y, z_])\n",
    "\n",
    "vae.compile(optimizer='adam', loss=gumbel_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "INPUT_DIM = (28,28,1)\n",
    "DATA_DIM = 784 # MNIST: 28x28x1\n",
    "M = 7 #10\n",
    "N = 42 #30\n",
    "nb_epoch = 50 #100\n",
    "epsilon_std = 0.01\n",
    "\n",
    "anneal_rate = 0.0003\n",
    "min_temperature = 0.1 #0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 32)        544       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 294)               922278    \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 294)               0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 6)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 14, 14, 32)        800       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 28, 28, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 961,223\n",
      "Trainable params: 961,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tau = K.variable(5.0, name=\"temperature\")\n",
    "ACTIV = \"relu\"\n",
    "\n",
    "# x = Input(batch_shape=(batch_size, data_dim ))\n",
    "x = Input(shape=INPUT_DIM)\n",
    "# h = Dense(256, activation='relu')(Dense(512, activation='relu')(x))\n",
    "h = Conv2D(filters=32, kernel_size=4, strides=2, padding='same', activation=ACTIV)(x)\n",
    "h = Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation=ACTIV)(h)\n",
    "# h = Conv2D(filters=64, kernel_size=3, strides=2, padding='valid', activation=ACTIV)(h)\n",
    "h = Flatten()(h)\n",
    "\n",
    "logits_y = Dense(M*N, activation=None)(h)\n",
    "\n",
    "\n",
    "# z = Lambda(sampling, output_shape=(M*N,))(logits_y)\n",
    "\n",
    "z_lay = Lambda(sampling, output_shape=(M*N,))\n",
    "z = z_lay(logits_y)\n",
    "z_ = Activation(None)(z)\n",
    "\n",
    "# generator = Sequential()\n",
    "# generator.add(Dense(256, activation='relu', input_shape=(N*M, )))\n",
    "# generator.add(Dense(512, activation='relu'))\n",
    "# generator.add(Dense(data_dim, activation='sigmoid'))\n",
    "# x_hat = generator(z)\n",
    "\n",
    "z_dec = Reshape( (M,M,-1), input_shape=(N*M,) )\n",
    "z_h = Conv2DTranspose(filters=32, kernel_size=2, strides=2, padding=\"same\", activation=ACTIV)\n",
    "z_h2 = Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\", activation=ACTIV)\n",
    "x_hat = Conv2D(filters=1, kernel_size=3, strides=1, padding=\"same\", activation=\"sigmoid\")\n",
    "# x_hat = Conv2DTranspose(filters=1, kernel_size=3, strides=2, padding=\"same\", activation=\"sigmoid\")\n",
    "\n",
    "# generator = Sequential()\n",
    "# generator.add( z_dec )\n",
    "# generator.add( z_h )\n",
    "# generator.add( z_h2 )\n",
    "# generator.add( z_h3 )\n",
    "# x_hat = generator(z)\n",
    "\n",
    "# x_hat = Dense(data_dim, activation='softmax')(Dense(512, activation='relu')(Dense(256, activation='relu')(z)))\n",
    "\n",
    "decoded_x = x_hat(z_h2(z_h(z_dec( z ))))\n",
    "\n",
    "decode_input = Input( shape=(M*N,) )\n",
    "decoder = x_hat(z_h2(z_h(z_dec( decode_input ))))\n",
    "generator = Model(decode_input, decoder)\n",
    "\n",
    "vae_test = Model(x, [decoded_x, logits_y, z_])\n",
    "vae = Model(x, decoded_x)\n",
    "vae.compile(optimizer='adam', loss=gumbel_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "INPUT_DIM = (64,64,3)\n",
    "DATA_DIM = 12288 # MNIST: 28x28x1\n",
    "M = 8\n",
    "N = 12\n",
    "nb_epoch = 50 #100\n",
    "epsilon_std = 0.01\n",
    "\n",
    "anneal_rate = 0.0003\n",
    "min_temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        1568      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        32832     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 96)                1572960   \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1, 1, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 2, 2, 32)          49184     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 4, 4, 32)          16416     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 8, 8, 16)          8208      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 32, 32, 16)        4112      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 64, 64, 3)         771       \n",
      "=================================================================\n",
      "Total params: 1,686,051\n",
      "Trainable params: 1,686,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tau = K.variable(5.0, name=\"temperature\")\n",
    "ACTIV = \"relu\"\n",
    "\n",
    "# x = Input(batch_shape=(batch_size, data_dim ))\n",
    "x = Input(shape=INPUT_DIM)\n",
    "# h = Dense(256, activation='relu')(Dense(512, activation='relu')(x))\n",
    "h = Conv2D(filters=32, kernel_size=4, strides=2, padding='same', activation=ACTIV)(x)\n",
    "h = Conv2D(filters=64, kernel_size=4, strides=2, padding='same', activation=ACTIV)(h)\n",
    "# h = Conv2D(filters=64, kernel_size=3, strides=2, padding='valid', activation=ACTIV)(h)\n",
    "h = Flatten()(h)\n",
    "\n",
    "logits_y = Dense(M*N, activation=None)(h)\n",
    "\n",
    "# z = Lambda(sampling, output_shape=(M*N,))(logits_y)\n",
    "z_lay = Lambda(sampling, output_shape=(M*N,))\n",
    "z = z_lay(logits_y)\n",
    "z_ = Activation(None)(z)\n",
    "\n",
    "# z = Reshape((1,1,N*M))(z)\n",
    "# z = Conv2DTranspose(filters=32, kernel_size=6, strides=4, padding=\"same\")(z)\n",
    "# z = Conv2DTranspose(filters=32, kernel_size=3, strides=4, padding=\"same\")(z)\n",
    "# z = Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\")(z)\n",
    "# x_hat = Conv2DTranspose(filters=3, kernel_size=3, strides=2, padding=\"same\")(z)\n",
    "\n",
    "z_1 = Reshape((1,1,N*M))\n",
    "z_2 = Conv2DTranspose(filters=32, kernel_size=4, strides=2, padding=\"same\", activation=ACTIV)\n",
    "z_3 = Conv2DTranspose(filters=32, kernel_size=4, strides=2, padding=\"same\", activation=ACTIV)\n",
    "z_4 = Conv2DTranspose(filters=16, kernel_size=4, strides=2, padding=\"same\", activation=ACTIV)\n",
    "z_5 = Conv2DTranspose(filters=16, kernel_size=4, strides=4, padding=\"same\", activation=ACTIV)\n",
    "x_hat = Conv2DTranspose(filters=3, kernel_size=4, strides=2, padding=\"same\", activation=\"sigmoid\")\n",
    "\n",
    "decoded_x = x_hat(z_5(z_4(z_3(z_2(z_1( z ))))))\n",
    "\n",
    "\n",
    "# x_hat = Dense(data_dim, activation='softmax')(Dense(512, activation='relu')(Dense(256, activation='relu')(z)))\n",
    "\n",
    "decode_input = Input( shape=(M*N,) )\n",
    "decoder = x_hat(z_5(z_4(z_3(z_2(z_1( decode_input ))))))\n",
    "generator = Model(decode_input, decoder)\n",
    "\n",
    "vae_test = Model(x, [decoded_x, logits_y, z_])\n",
    "vae = Model(x, decoded_x)\n",
    "vae.compile(optimizer='adam', loss=gumbel_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1) (2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# train the VAE on MNIST digits\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "# vectorize\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:]))) \n",
    "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "# give extra third dimensioin\n",
    "x_train = x_train.reshape( (len(x_train),28,28,1  ) )\n",
    "x_test = x_test.reshape( (len(x_test),28,28,1  ) )\n",
    "\n",
    "# reduce data set size\n",
    "x_train = x_train[:10000]\n",
    "x_test = x_test[:2000]\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## race car data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = \"world_models_data\"\n",
    "data1 = \"small_obs_data_car_racing_1.npy\"\n",
    "np_dat = np.load(os.path.join(data_dir, data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 64, 64, 3) (2000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np_dat[:8000]\n",
    "x_test = np_dat[8000:]\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 4s 510us/step - loss: 528.2675 - val_loss: 338.8983\n",
      "1 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 418us/step - loss: 150.6017 - val_loss: 132.0448\n",
      "2 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 435us/step - loss: 88.1371 - val_loss: 99.3534\n",
      "3 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 416us/step - loss: 68.4500 - val_loss: 81.2372\n",
      "4 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 433us/step - loss: 52.6427 - val_loss: 67.9571\n",
      "5 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 404us/step - loss: 42.4511 - val_loss: 56.5604\n",
      "6 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 402us/step - loss: 30.8567 - val_loss: 45.4221\n",
      "7 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 23.6776 - val_loss: 39.6644\n",
      "8 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 19.6200 - val_loss: 36.9107\n",
      "9 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 401us/step - loss: 17.1468 - val_loss: 35.3314\n",
      "10 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 15.4537 - val_loss: 34.2153\n",
      "11 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 13.8679 - val_loss: 33.0976\n",
      "12 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 12.7749 - val_loss: 34.6225\n",
      "13 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 11.9183 - val_loss: 33.0796\n",
      "14 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 11.1819 - val_loss: 33.1038\n",
      "15 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 10.4576 - val_loss: 33.0230\n",
      "16 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 9.8351 - val_loss: 31.1505\n",
      "17 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 9.2218 - val_loss: 31.8053\n",
      "18 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 8.7629 - val_loss: 31.5413\n",
      "19 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 8.3618 - val_loss: 31.1883\n",
      "20 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 7.8357 - val_loss: 31.6979\n",
      "21 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 396us/step - loss: 7.1570 - val_loss: 31.7293\n",
      "22 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 397us/step - loss: 6.1177 - val_loss: 30.7331\n",
      "23 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 399us/step - loss: 4.8740 - val_loss: 29.8622\n",
      "24 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 424us/step - loss: 3.9292 - val_loss: 29.7473\n",
      "25 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 413us/step - loss: 3.4331 - val_loss: 29.2792\n",
      "26 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 4s 442us/step - loss: 3.1370 - val_loss: 28.7988\n",
      "27 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 429us/step - loss: 2.7472 - val_loss: 29.1638\n",
      "28 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 431us/step - loss: 2.5949 - val_loss: 29.1143\n",
      "29 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 425us/step - loss: 2.2767 - val_loss: 29.9102\n",
      "30 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 408us/step - loss: 2.0351 - val_loss: 29.3885\n",
      "31 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 404us/step - loss: 1.8583 - val_loss: 30.9804\n",
      "32 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 406us/step - loss: 1.7351 - val_loss: 29.7577\n",
      "33 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 401us/step - loss: 1.5961 - val_loss: 29.7750\n",
      "34 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 398us/step - loss: 1.4528 - val_loss: 30.3188\n",
      "35 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 399us/step - loss: 1.3252 - val_loss: 29.7437\n",
      "36 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 1.1732 - val_loss: 29.8828\n",
      "37 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 413us/step - loss: 1.1290 - val_loss: 29.3733\n",
      "38 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 402us/step - loss: 0.8617 - val_loss: 29.0328\n",
      "39 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 403us/step - loss: 0.7117 - val_loss: 31.4108\n",
      "40 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 404us/step - loss: 0.6852 - val_loss: 30.4634\n",
      "41 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 0.5971 - val_loss: 30.1730\n",
      "42 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 0.4568 - val_loss: 31.4143\n",
      "43 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 400us/step - loss: 0.2698 - val_loss: 30.5005\n",
      "44 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 400us/step - loss: 0.2258 - val_loss: 30.4398\n",
      "45 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 404us/step - loss: 0.0970 - val_loss: 31.0507\n",
      "46 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 402us/step - loss: 0.0348 - val_loss: 31.7822\n",
      "47 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 408us/step - loss: 0.0595 - val_loss: 31.3900\n",
      "48 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 405us/step - loss: -0.0720 - val_loss: 31.3841\n",
      "49 / 50\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: -0.1584 - val_loss: 31.7602\n"
     ]
    }
   ],
   "source": [
    "for e in range(nb_epoch):\n",
    "    print(e, \"/\", nb_epoch)\n",
    "    train_hist = vae.fit(x_train, x_train, \n",
    "        shuffle=True, \n",
    "        epochs=1, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test))\n",
    "    K.set_value(tau, np.max([K.get_value(tau) * np.exp(- anneal_rate * e), min_temperature]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save_weights('model3_vae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_y = K.max(K.reshape(logits_y, (-1, N, M)), axis=-1, keepdims=True)\n",
    "argmax_y = K.equal(K.reshape(logits_y, (-1, N, M)), argmax_y)\n",
    "# encoder = K.function([x], [argmax_y, x_hat])\n",
    "encoder = K.function([x], [argmax_y, decoded_x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x18a0aa25860>, (-0.5, 63.5, 63.5, -0.5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x188470dca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_idx, try: from 160-180\n",
    "test_idx = 171\n",
    "_batch = 300\n",
    "code, x_hat_test = encoder([x_test[:_batch]])\n",
    "\n",
    "_x_hat, _logits, _z = vae_test.predict(x_test[:_batch])\n",
    "\n",
    "subplot(331)\n",
    "title(\"Input image\")\n",
    "# imshow(x_test[test_idx].reshape(28, 28), cmap='gray'), axis('off')\n",
    "imshow(x_test[test_idx].reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "subplot(334)\n",
    "title(\"true\")\n",
    "imshow(_z[test_idx].reshape(N, M), cmap='gray'), axis('off')\n",
    "\n",
    "subplot(335)\n",
    "title(\"decoder\")\n",
    "img_true = generator.predict(np.reshape(_z[test_idx], (1,-1)) )\n",
    "# imshow(img_true.reshape(28, 28), cmap='gray'), axis('off')\n",
    "imshow(img_true.reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "subplot(336)\n",
    "title(\"full network\")\n",
    "# imshow(x_hat_test[test_idx].reshape(28, 28), cmap='gray'), axis('off')\n",
    "imshow(x_hat_test[test_idx].reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "\n",
    "# imshow(x_hat_test[test_idx].reshape(28, 28), cmap='gray'), axis('off')\n",
    "# imshow(x_hat_test[test_idx].reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "subplot(337)\n",
    "title(\"binary\")\n",
    "imshow(code[test_idx].reshape(N, M), cmap='gray'), axis('off')\n",
    "\n",
    "subplot(338)\n",
    "title(\"binary x_hat\")\n",
    "img_binary = generator.predict(np.reshape(code[test_idx], (1,-1)) )\n",
    "# imshow(img_binary.reshape(28, 28), cmap='gray'), axis('off')\n",
    "imshow(img_binary.reshape(64, 64, 3), cmap='gray'), axis('off')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from ipywidgets import interactive\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181fd948e58d47a08961638c68adfbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, continuous_update=False, description='z7', max=3), IntSlider(value=2,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# N = 10\n",
    "# M = 5\n",
    "\n",
    "img_code = np.zeros( (N,M) )\n",
    "\n",
    "def f(*args,**kwargs):\n",
    "#     print(kwargs)\n",
    "    for i, key in enumerate(kwargs):\n",
    "#         print( kwargs[key] )\n",
    "        zero_row = np.zeros((1,M))\n",
    "        zero_row[0, kwargs[key] ] = 1\n",
    "        img_code[i] = zero_row\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img_code, cmap=\"gray\")\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    img_binary = generator.predict(np.reshape(img_code, (1,-1)) )\n",
    "#     plt.imshow(img_binary.reshape(28, 28), cmap='gray')\n",
    "    plt.imshow(img_binary.reshape(64, 64, 3), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "kw_dict = {}\n",
    "for n in range(N):\n",
    "    kw_dict[\"z\"+str(n)] = widgets.IntSlider(description=\"z\"+str(n), min=0, max=(M-1), value=int(M/2), continuous_update=False)\n",
    "\n",
    "interactive_plot = interactive(f, **kw_dict)\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '350px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sample 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1de17e4a198>, (-0.5, 9.5, 29.5, -0.5))"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG4AAAD8CAYAAACW9ZGzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA0BJREFUeJzt3cGKo0AUQNHYzP//cnrbs4gVFLWunrNt6AQuD+pFTZb3\n+/2i5+fqN8A2wkUJFyVclHBRwkUJFyVclHBR/858sWVZfEzzer0Gn1Yt3/wPExclXJRwUcJFCRcl\nXNSp68CdrB3pl2X9RL/2928vbJu4KOGihIsSLkq4KOGihIuaZo8b7S+j3ehsV78fExclXJRwUcJF\nCRclXNQ068BRx+s9l19mZuKihIsSLkq4KOGihIuaZh0Y2XqsLx/515i4KOGihIsSLkq4KOGiMuvA\nEcf62g1Kf5m4KOGihIsSLkq4KOGihIs6dY+b7Y6rmfe0ERMXJVyUcFHCRQkXJVyUcFHCRQkXJVyU\ncFHCRQkXdfYvfZz5crvNdjXjLxMXJVyUcFHCRQkXJVxU5qGPK2w98p/xMImJixIuSrgo4aKEixIu\nSrgoe9yKmb8/zMRFCRclXJRwUcJFCReVWQeuuOPq6ju51pi4KOGihIsSLkq4KOGiMuuAr/b9n4mL\nEi5KuCjhooSLEi4qsw4ccXVg5uP+iImLEi5KuCjhooSLEi5KuKjML32Ud64jmLgo4aKEixIuSrgo\n4aJ8te8BfJcXHwkXJVyUcFHCRQkXlbnLq2R03B+tC98wcVHCRQkXJVyUcFHCRQkXdfs9bsZfXVx7\n3W93PBMXJVyUcFHCRQkXJVzU7deBK4787vLiI+GihIsSLkq4KOGibr8OHOXqqw4mLkq4KOGihIsS\nLkq4qNuvA0cd269+nt3ERQkXJVyUcFHCRQkXJVzU7fc4d3kxFeGihIsSLkq4KOGibr8O7LH1kpC7\nvPhIuCjhooSLEi5KuKhHrwNnfIp/FBMXJVyUcFHCRQkXJVzUo9eBPcd9z4CziXBRwkUJFyVclHBR\nwkU9eo/bY8+vdXjo48GEixIuSrgo4aKEixIuSrgo4aKEixIuSrgo4aKEixIuSrgo4aKEixIuSrio\nR98sdNRNPR764CPhooSLEi5KuCjhooSLevQeN9q3rn5Af42JixIuSrgo4aKEixIuahld2mBOJi5K\nuCjhooSLEi5KuCjhooSLEi5KuCjhooSLEi5KuCjhooSLEi5KuCjhooSLEi5KuCjhon4BnbZgZgMz\nSZgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1de16ab8828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = np.zeros( (N,M) )\n",
    "\n",
    "for i in range(N):\n",
    "    sample[i, np.random.randint(0,M)] = 1.0\n",
    "\n",
    "# print(sample)\n",
    "# imshow(sample, cmap='gray'), axis('off')\n",
    "imshow(code[test_idx].reshape(N, M), cmap='gray'), axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def softmaxx(x):\n",
    "#     \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "def softmaxx(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    arr = []\n",
    "    for row in x:\n",
    "        e_x = np.exp(row - np.max(row))\n",
    "        e_x = e_x / e_x.sum()\n",
    "        arr.append(e_x)\n",
    "#         print(e_x)\n",
    "    return np.asarray(arr)\n",
    "\n",
    "\n",
    "def sampl(logits_y, tau):\n",
    "#     U = K.random_uniform(K.shape(logits_y), 0, 1)\n",
    "#     print(\"LOGITS_Y\")\n",
    "#     print(logits_y)\n",
    "    U = np.random.uniform(0, 1, logits_y.shape)\n",
    "#     print(\"U !!!\")\n",
    "#     print(U)\n",
    "    y = logits_y - np.log(-np.log(U + 1e-20) + 1e-20) # logits + gumbel noise\n",
    "#     print(\"y: logits minus gumbel\")\n",
    "#     print(y)\n",
    "    y = softmaxx(np.reshape(y, (-1, N, M)) / tau)\n",
    "#     print(\"y after softmax\")\n",
    "#     print(y)\n",
    "    y = np.reshape(y, (-1, N*M))\n",
    "#     print(\"y after reshape\")\n",
    "#     print(y)\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20): \n",
    "  \"\"\"Sample from Gumbel(0, 1)\"\"\"\n",
    "  U = tf.random_uniform(shape,minval=0,maxval=1)\n",
    "  return -tf.log(-tf.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature): \n",
    "  \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
    "  y = logits + sample_gumbel(tf.shape(logits))\n",
    "  return tf.nn.softmax( y / temperature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGITS_Y\n",
      "[ 0.34383575  0.94892719  0.42020285  0.95438047  0.87347585  0.571351\n",
      "  0.13958841  0.56617047  0.463364    0.41711555  0.92501778  0.74537507\n",
      "  0.78030203  0.57333708  0.88866286  0.77348239  0.40044252  0.52112064\n",
      "  0.96502015  0.16092027  0.05671647  0.17942218  0.99459745  0.80318646\n",
      "  0.76559526  0.53798436  0.64749067  0.84097111  0.90487155  0.5699846\n",
      "  0.27000314  0.18780187  0.91074068  0.87836262  0.94238966  0.08558775\n",
      "  0.47190035  0.87476978  0.83202187  0.44219694  0.0422646   0.41115651\n",
      "  0.00842397  0.72800203  0.11273228  0.45575335  0.29622134  0.09444701\n",
      "  0.8617085   0.02848176  0.41319634  0.04314811  0.16704191  0.82344977\n",
      "  0.51225001  0.81893367  0.08099949  0.86070965  0.80678421  0.77462458\n",
      "  0.11124669  0.68586619  0.65344374  0.86040751  0.90271618  0.66211689\n",
      "  0.97129203  0.71446682  0.79617341  0.88864883  0.51802012  0.00172061\n",
      "  0.25666503  0.30997656  0.36319418  0.12101082  0.85507319  0.59306272\n",
      "  0.71723007  0.44005196  0.61931873  0.08814299  0.23257993  0.28291901\n",
      "  0.99046461  0.88388076  0.98289907  0.58722471  0.52641645  0.23380091\n",
      "  0.76926913  0.58088948  0.63814542  0.79481485  0.7804607   0.24301469\n",
      "  0.80219988  0.46359635  0.12745381  0.87330093  0.84493167  0.47649123\n",
      "  0.49175921  0.20556464  0.1708891   0.6682063   0.37442154  0.21974778\n",
      "  0.12169858  0.96764946  0.6679697   0.09964186  0.01884825  0.42539811\n",
      "  0.59520289  0.5631137   0.33818521  0.70691643  0.2541997   0.45076275\n",
      "  0.82708747  0.76282996  0.13105242  0.15455181  0.09811126  0.52874148\n",
      "  0.32042449  0.09312049  0.50385319  0.29344181  0.34676473  0.47913363\n",
      "  0.2096174   0.75292952  0.90339817  0.62149749  0.07601298  0.42430594\n",
      "  0.61981654  0.30553238  0.88923011  0.6683534   0.95810957  0.80950272\n",
      "  0.47892854  0.21745957  0.51378139  0.63139622  0.59874168  0.67429401\n",
      "  0.72056111  0.03317238  0.82128994  0.41715262  0.85780739  0.92151773\n",
      "  0.29876804  0.61440221  0.55707665  0.93208998  0.04589325  0.96709615\n",
      "  0.48511657  0.42423363  0.82175468  0.09805713  0.58795049  0.93641893\n",
      "  0.19849032  0.76116732  0.04066255  0.16018387  0.65913557  0.35232396\n",
      "  0.018603    0.50611313  0.06575202  0.33593128  0.16690781  0.40899554\n",
      "  0.46238912  0.92987485  0.62053746  0.02912147  0.34495916  0.7402112\n",
      "  0.91787087  0.62624719  0.34934525  0.55410236  0.50377459  0.17915992\n",
      "  0.5688292   0.48324789  0.10069444  0.29166853  0.56724896  0.70542824\n",
      "  0.69256543  0.1064081   0.14367835  0.39235259  0.31753094  0.57740658\n",
      "  0.87847681  0.77602608  0.01913303  0.77849368  0.43094818  0.65944998\n",
      "  0.75587534  0.48739683  0.1235594   0.01585197  0.50016479  0.25424301\n",
      "  0.9558384   0.66712643  0.69602747  0.22291665  0.8237805   0.23410254\n",
      "  0.7876335   0.11308955  0.18146412  0.55370528  0.85782867  0.06534946\n",
      "  0.99257259  0.49190909  0.7008973   0.53938017  0.09375109  0.10802076\n",
      "  0.97481163  0.50504194  0.1380839   0.50677726  0.88000705  0.06281845\n",
      "  0.07670508  0.32935287  0.82552201  0.36129948  0.54544357  0.91633933\n",
      "  0.74757079  0.7218691   0.26311673  0.50198059  0.00751842  0.27161064\n",
      "  0.05463158  0.29453463  0.72616499  0.9058934   0.51931062  0.87048115\n",
      "  0.21979446  0.47315357  0.99594974  0.92652631  0.01679969  0.59250515\n",
      "  0.89604061  0.88118036  0.42494664  0.1590062   0.0825894   0.37804693\n",
      "  0.78717963  0.70973782  0.06318474  0.83770287  0.35916094  0.62236818\n",
      "  0.70262467  0.21212627  0.04229292  0.43228391  0.63266222  0.70362333\n",
      "  0.97455854  0.85486436  0.59163941  0.87959887  0.89248854  0.07132521\n",
      "  0.65074611  0.1995983   0.33739191  0.41061578  0.65620525  0.89441296\n",
      "  0.43672308  0.69503385  0.53645844  0.40843143  0.17641917  0.7056799 ]\n",
      "U !!!\n",
      "[ 0.18837457  0.70086647  0.1271422   0.76649455  0.13590682  0.95642727\n",
      "  0.93680168  0.00658049  0.74152516  0.60629176  0.26685884  0.57140982\n",
      "  0.04486089  0.7330901   0.74042864  0.03345507  0.9287096   0.03110689\n",
      "  0.93469814  0.09457855  0.61285182  0.43550989  0.36162238  0.58099556\n",
      "  0.37046348  0.3982817   0.78076352  0.96095455  0.3727099   0.28784878\n",
      "  0.72340886  0.63395711  0.64703696  0.92068734  0.0269876   0.83591623\n",
      "  0.10928973  0.29342987  0.9345378   0.90979947  0.46079387  0.17266516\n",
      "  0.99518287  0.64795097  0.81346266  0.1665627   0.15137523  0.03254678\n",
      "  0.19612551  0.44166682  0.10626299  0.37145402  0.58578236  0.9915032\n",
      "  0.27475769  0.18400777  0.98160425  0.52730313  0.18145411  0.91636445\n",
      "  0.41762819  0.61167728  0.44962833  0.74766836  0.60212114  0.25066866\n",
      "  0.41082299  0.1477073   0.59883947  0.15678245  0.72933471  0.53241453\n",
      "  0.715001    0.62372191  0.82761313  0.27158547  0.0227614   0.12019386\n",
      "  0.10413265  0.05330067  0.69424641  0.1127775   0.89359076  0.79007358\n",
      "  0.61979732  0.44992399  0.49410563  0.76269298  0.280864    0.00627749\n",
      "  0.56360068  0.83420799  0.95439747  0.63186276  0.76242657  0.6582563\n",
      "  0.28890739  0.46814111  0.43618698  0.61968078  0.3289999   0.03521798\n",
      "  0.6690987   0.10660118  0.51583706  0.5383264   0.09244838  0.08263033\n",
      "  0.34306059  0.21663983  0.90272103  0.64535916  0.01025424  0.92325112\n",
      "  0.20985656  0.06297752  0.85612859  0.1503469   0.38881677  0.75800086\n",
      "  0.9247564   0.494567    0.49844107  0.3349092   0.85107764  0.03320158\n",
      "  0.94079796  0.92343855  0.52305151  0.01491924  0.78165621  0.21019991\n",
      "  0.9686666   0.16063754  0.91881776  0.14805564  0.04323038  0.62401447\n",
      "  0.14991149  0.76944051  0.00985224  0.65938986  0.27176384  0.7224134\n",
      "  0.25714348  0.6089626   0.72630321  0.72497331  0.20366037  0.71164521\n",
      "  0.21585557  0.88924912  0.30131544  0.63783878  0.19211501  0.83371987\n",
      "  0.12876521  0.48596515  0.83657134  0.658091    0.16988211  0.74772773\n",
      "  0.94504313  0.9062561   0.09175357  0.37317545  0.43366836  0.26822287\n",
      "  0.35827446  0.60946706  0.43507064  0.89707322  0.9287651   0.40166992\n",
      "  0.87664752  0.92344225  0.63141546  0.71265473  0.12558458  0.7997866\n",
      "  0.64291201  0.80042451  0.41632738  0.29856423  0.91504715  0.92861849\n",
      "  0.46683797  0.22916743  0.21187133  0.57578827  0.93823038  0.88256403\n",
      "  0.23692544  0.48226452  0.57012684  0.09366286  0.18509144  0.09837227\n",
      "  0.27195999  0.34506482  0.54734847  0.40815763  0.47946219  0.28487683\n",
      "  0.16459814  0.97816579  0.66101967  0.42234727  0.11648556  0.52916647\n",
      "  0.49278899  0.33424093  0.24433853  0.2205447   0.27553404  0.49405928\n",
      "  0.10364884  0.14380799  0.01017396  0.85823498  0.74574067  0.57701674\n",
      "  0.38920615  0.20401484  0.39919053  0.21256709  0.36953915  0.58101258\n",
      "  0.00790821  0.5177698   0.74346048  0.61328013  0.07860877  0.53028081\n",
      "  0.70644828  0.66781451  0.08529712  0.72850353  0.26122457  0.00137426\n",
      "  0.97752084  0.2576183   0.20907863  0.18806753  0.75304324  0.34594412\n",
      "  0.85984811  0.27820837  0.49644328  0.11146543  0.42471182  0.9165709\n",
      "  0.26384799  0.49885483  0.82173121  0.3365377   0.92371109  0.61734791\n",
      "  0.638395    0.12351731  0.79833229  0.20934906  0.18633459  0.5958549\n",
      "  0.68173404  0.73039036  0.05553844  0.06966247  0.25515172  0.16835681\n",
      "  0.55305619  0.91926542  0.52206115  0.3229384   0.98756132  0.96186527\n",
      "  0.0438585   0.54621571  0.92904105  0.94231841  0.68685066  0.3468898\n",
      "  0.27614297  0.43462217  0.97905797  0.87540217  0.67265813  0.08009913\n",
      "  0.98262616  0.71226935  0.76800318  0.70449205  0.2574658   0.48030396\n",
      "  0.91275211  0.82183725  0.66112151  0.09746557  0.40534806  0.98124349]\n",
      "y: logits minus gumbel\n",
      "[ -1.68582345e-01   1.98333191e+00  -3.03691312e-01   2.27891132e+00\n",
      "   1.82438011e-01   3.68248230e+00   2.86860166e+00  -1.04798557e+00\n",
      "   1.67052124e+00   1.10947513e+00   6.46601918e-01   1.32582124e+00\n",
      "  -3.52450453e-01   1.74295139e+00   2.09088379e+00  -4.49572804e-01\n",
      "   3.00468447e+00  -7.23127853e-01   3.66017915e+00  -6.97031188e-01\n",
      "   7.70817465e-01   3.64261570e-01   9.77588178e-01   1.41381000e+00\n",
      "   7.72619449e-01   6.20718640e-01   2.04390420e+00   4.06415216e+00\n",
      "   9.18002488e-01   3.50592054e-01   1.39769194e+00   9.73560129e-01\n",
      "   1.74234138e+00   3.37168731e+00  -3.41976542e-01   1.80469059e+00\n",
      "  -3.22788859e-01   6.70917824e-01   3.52464369e+00   2.80102372e+00\n",
      "   2.97409176e-01  -1.52110344e-01   5.34158795e+00   1.56285047e+00\n",
      "   1.69040387e+00  -1.27792915e-01  -3.39293305e-01  -1.13667687e+00\n",
      "   3.73741892e-01   2.30353820e-01  -3.94099807e-01   5.28649791e-02\n",
      "   7.92891350e-01   5.58725221e+00   2.56162545e-01   2.92563111e-01\n",
      "   4.06736590e+00   1.30702849e+00   2.72191781e-01   3.21255842e+00\n",
      "   2.46878871e-01   1.39605688e+00   8.77420171e-01   2.09554158e+00\n",
      "   1.58137558e+00   3.37411268e-01   1.08828345e+00   6.60436769e-02\n",
      "   1.46411746e+00   2.71898947e-01   1.67122846e+00   4.63227801e-01\n",
      "   1.34888379e+00   1.06064552e+00   2.02809478e+00  -1.44025548e-01\n",
      "  -4.75361941e-01  -1.57716055e-01  -9.90589615e-02  -6.35566801e-01\n",
      "   1.62737306e+00  -6.92253985e-01   2.41731648e+00   1.72841493e+00\n",
      "   1.72785054e+00   1.10867990e+00   1.33244810e+00   1.89323132e+00\n",
      "   2.87490331e-01  -1.38969483e+00   1.32542466e+00   2.28864325e+00\n",
      "   3.70269080e+00   1.57333897e+00   2.08517849e+00   1.11490367e+00\n",
      "   5.85759457e-01   7.39368946e-01   3.14163856e-01   1.61029383e+00\n",
      "   7.39043252e-01  -7.31333684e-01   1.40350107e+00  -6.00313157e-01\n",
      "   5.83432691e-01   1.14738756e+00  -4.93143072e-01  -6.93890813e-01\n",
      "   5.41817952e-02   5.42696090e-01   2.94740769e+00   9.25296322e-01\n",
      "  -1.50286476e+00   2.95295322e+00   1.49664207e-01  -4.53918759e-01\n",
      "   2.20035839e+00   6.77978804e-02   3.11143585e-01   1.73424512e+00\n",
      "   3.37525440e+00   1.11370370e+00   4.93070305e-01   6.48063240e-02\n",
      "   1.92289869e+00  -6.96549806e-01   3.11686558e+00   2.62322097e+00\n",
      "   9.37601528e-01  -1.14285711e+00   1.74780625e+00   3.46425532e-02\n",
      "   3.65681300e+00   1.49376255e-01   3.37242185e+00  -2.56932388e-02\n",
      "  -1.06859570e+00   1.17596882e+00  -2.08314748e-02   1.64459344e+00\n",
      "  -6.41176868e-01   1.54436550e+00   6.93577036e-01   1.93294763e+00\n",
      "   1.72826358e-01   9.18642078e-01   1.65387931e+00   1.76577941e+00\n",
      "   1.34189437e-01   1.75258676e+00   2.93239443e-01   2.17552941e+00\n",
      "   6.39303774e-01   1.21639455e+00   3.57237531e-01   2.62604785e+00\n",
      "  -4.18956941e-01   9.40661068e-01   2.28056004e+00   1.80337852e+00\n",
      "  -5.26582665e-01   2.20250334e+00   3.35819388e+00   2.74260928e+00\n",
      "  -4.89732245e-02   1.12453666e-01   7.67705115e-01   6.61869938e-01\n",
      "   1.72378285e-01   1.46402070e+00   2.24288724e-01   2.38010388e+00\n",
      "   3.26418575e+00   4.44302603e-01   2.04620923e+00   3.03626383e+00\n",
      "   8.42734806e-01   1.41839990e+00  -5.62945302e-01   1.90774065e+00\n",
      "   1.27940616e+00   2.43219504e+00   7.52603239e-01  -1.60481999e-01\n",
      "   2.76655661e+00   3.34312750e+00   1.18997748e+00   2.38740779e-01\n",
      "  -9.00549172e-02   1.14828194e+00   3.25640770e+00   2.25921012e+00\n",
      "   2.04179297e-01   7.98969378e-01   6.77132207e-01  -5.70399807e-01\n",
      "   4.43533074e-02  -1.35706219e-01   4.28586852e-01   4.43510884e-02\n",
      "   6.50064458e-01   5.02053811e-01   6.25292962e-01   3.49714690e-01\n",
      "   2.88332779e-01   4.58928548e+00   9.01090730e-01   9.27077941e-01\n",
      "  -3.34514080e-01   1.11129593e+00   1.10164679e+00   3.95827087e-01\n",
      "  -2.19463182e-01  -3.97353023e-01   2.46263866e-01   6.03658983e-01\n",
      "   1.37492779e-01   4.81156306e-03  -8.27400187e-01   2.10103600e+00\n",
      "   2.05007607e+00   8.32150470e-01   8.45637554e-01  -3.50369287e-01\n",
      "   2.66677347e-01   1.16420101e-01   8.62340259e-01   6.76026970e-01\n",
      "  -5.84311859e-01   9.10118264e-01   1.91680886e+00   1.25490902e+00\n",
      "  -8.39700361e-01   5.63177427e-01   2.03178704e+00   1.41201416e+00\n",
      "  -7.62733568e-01   1.65637931e+00   5.85566753e-01  -1.82271099e+00\n",
      "   3.86052554e+00   2.46099902e-02   3.77607507e-01  -1.52095343e-01\n",
      "   1.80551900e+00   8.56677038e-01   2.63804943e+00   4.75489685e-01\n",
      "   6.19383125e-01  -2.83764343e-01   1.62601068e-01   2.71212705e+00\n",
      "  -2.32336829e-01   6.57744962e-01   2.35406259e+00   8.20592143e-01\n",
      "   3.05312270e+00   1.59962336e+00   1.02097669e+00  -2.64667704e-01\n",
      "   2.48658131e+00   4.79438075e-01  -5.02119894e-01   1.25075229e+00\n",
      "   1.85545894e+00   2.03898183e+00  -6.36545064e-01  -8.20857658e-01\n",
      "  -2.29221911e-01  -1.99504000e-01   1.31092894e+00   3.18453124e+00\n",
      "   4.94012957e-01   7.15225362e-01   4.73985303e+00   3.86962071e+00\n",
      "  -4.37381232e-01   7.15080783e-01   2.65137123e+00   3.25554226e+00\n",
      "   1.61179056e+00   6.46536124e-01   7.22371612e-01   1.03725207e+00\n",
      "   4.44707277e+00   2.89646479e+00   1.81752225e+00  -8.54713971e-01\n",
      "   4.69478542e+00   1.28047144e+00   1.66934429e+00   1.45964328e+00\n",
      "   3.51025860e-01   1.20456409e+00   2.83042671e+00   2.32358888e+00\n",
      "   1.41878836e+00  -4.36688104e-01   2.78441747e-01   4.67244174e+00]\n",
      "y after softmax\n",
      "[[[  9.26417769e-26   2.05329692e-16   2.39903227e-26   3.94581571e-15\n",
      "     3.09933780e-24   4.91776902e-09   1.43591724e-12   1.40477643e-29\n",
      "     8.99357254e-18   3.29109161e-20]\n",
      "  [  3.21445351e-22   2.86364506e-19   1.47325467e-26   1.85563437e-17\n",
      "     6.01926695e-16   5.57802966e-27   5.59924605e-12   3.61781484e-28\n",
      "     3.93465604e-09   4.69659067e-28]\n",
      "  [  1.11318773e-21   1.90949532e-23   8.80161186e-21   6.90318518e-19\n",
      "     1.13342903e-21   2.48140413e-22   3.76282358e-16   2.23531764e-07\n",
      "     4.85048144e-21   1.66553071e-23]\n",
      "  [  5.87556566e-19   8.45412403e-21   1.84434935e-17   2.19787324e-10\n",
      "     1.63593275e-26   3.44050611e-17   1.98196734e-26   4.09930077e-22\n",
      "     1.01457409e-09   7.30536882e-13]\n",
      "  [  9.78548460e-24   1.09230486e-25   7.89173357e-02   3.06424890e-18\n",
      "     1.09718896e-17   1.39300643e-25   1.68042293e-26   5.78663081e-30\n",
      "     2.09938027e-23   5.00454531e-24]\n",
      "  [  9.71397507e-27   8.48282261e-25   1.38814259e-21   9.20616457e-01\n",
      "     6.47814251e-24   9.32258060e-24   2.30832192e-07   2.37303038e-19\n",
      "     7.60439351e-24   4.47625327e-11]\n",
      "  [  5.90380508e-24   5.78027774e-19   3.23249665e-21   6.30626420e-16\n",
      "     3.68788693e-18   1.45985330e-23   2.66259833e-20   9.67775765e-25\n",
      "     1.14164747e-18   7.58215787e-24]\n",
      "  [  9.05740275e-18   5.13716456e-23   3.60643892e-19   2.01964794e-20\n",
      "     3.21258347e-16   1.18428354e-25   4.31002728e-27   1.03275801e-25\n",
      "     1.85670580e-25   8.68398671e-28]\n",
      "  [  5.84173801e-18   4.92640193e-28   1.57479053e-14   1.60457994e-17\n",
      "     1.59554940e-17   3.26502376e-20   3.05984379e-19   8.33968866e-17\n",
      "     8.86146123e-24   4.60874557e-31]\n",
      "  [  2.85231079e-19   4.34912670e-15   6.01911335e-09   3.40310263e-18\n",
      "     5.68546292e-16   3.47468795e-20   1.74932980e-22   8.12810362e-22\n",
      "     1.15703631e-23   4.92456601e-18]\n",
      "  [  8.10167396e-22   3.33279700e-28   6.22699310e-19   1.23544605e-27\n",
      "     1.70909687e-22   4.80830022e-20   3.60792538e-27   4.84642154e-28\n",
      "     8.59526448e-25   1.13723410e-22]\n",
      "  [  3.15776403e-12   5.21748927e-21   1.48625041e-31   3.33782502e-12\n",
      "     2.23323327e-24   5.34080318e-27   1.79881193e-15   9.84902299e-25\n",
      "     1.12261313e-23   1.70091088e-17]\n",
      "  [  2.27768841e-10   3.43324204e-20   6.92353392e-23   9.55874744e-25\n",
      "     1.12200195e-16   4.71925374e-28   1.71919806e-11   1.23439631e-13\n",
      "     5.90068453e-21   5.43983022e-30]\n",
      "  [  1.94794546e-17   7.06970667e-25   3.80441381e-09   2.22681188e-24\n",
      "     2.21407697e-10   3.86693061e-25   1.14313769e-29   6.39909235e-20\n",
      "     4.05957671e-25   6.93951719e-18]\n",
      "  [  8.21022277e-28   2.54709315e-18   5.14182739e-22   1.24061096e-16\n",
      "     2.81530878e-24   4.88160407e-21   7.61477829e-18   2.33148838e-17\n",
      "     1.91305748e-24   2.04332899e-17]\n",
      "  [  9.38584587e-24   1.40331406e-15   2.98821409e-22   9.58705221e-20\n",
      "     1.77997370e-23   1.26978918e-13   7.57606724e-27   6.08400845e-21\n",
      "     4.01141060e-15   3.39565927e-17]\n",
      "  [  2.58244596e-27   1.83781243e-15   1.92044289e-10   4.07334731e-13\n",
      "     3.06381605e-25   1.53932656e-24   1.07907505e-21   3.74468522e-22\n",
      "     2.80272236e-24   1.14054337e-18]\n",
      "  [  4.71003626e-24   1.08545167e-14   7.50117483e-11   4.25140410e-23\n",
      "     3.85056500e-16   7.67851058e-12   2.28508024e-21   7.22741813e-19\n",
      "     1.79518957e-27   9.64190954e-17]\n",
      "  [  1.80028407e-19   1.82742492e-14   9.27822785e-22   1.00458394e-25\n",
      "     5.17551272e-13   1.65184367e-10   7.36134598e-20   5.44237829e-24\n",
      "     2.03164190e-25   4.85149719e-20]\n",
      "  [  6.93984295e-11   3.24022812e-15   3.85203407e-24   1.47513110e-21\n",
      "     4.36212903e-22   1.66623330e-27   7.79066742e-25   1.28702231e-25\n",
      "     3.63312004e-23   7.79049454e-25]\n",
      "  [  3.32770462e-22   7.57430333e-23   2.59754769e-22   1.65098186e-23\n",
      "     8.93642976e-24   4.26544470e-05   4.09579313e-21   5.31127808e-21\n",
      "     1.76268418e-26   3.35156473e-20]\n",
      "  [  3.04328000e-20   2.61821853e-23   5.56973086e-26   9.40304353e-27\n",
      "     5.86760781e-24   2.09222482e-22   1.97730767e-24   5.24622667e-25\n",
      "     1.27525590e-28   6.66245241e-16]\n",
      "  [  4.00237667e-16   2.05557946e-21   2.35238245e-21   1.50423682e-26\n",
      "     7.19640671e-24   1.60161001e-24   2.78001319e-21   4.31418262e-22\n",
      "     1.44982818e-27   4.48274565e-21]\n",
      "  [  1.05571285e-16   1.40913089e-19   1.12766050e-28   1.39572284e-22\n",
      "     3.33341740e-16   6.78032134e-19   2.43467446e-28   7.80754740e-18\n",
      "     1.74596203e-22   6.06760721e-33]\n",
      "  [  2.91742774e-08   6.39485244e-25   2.18212319e-23   1.09246873e-25\n",
      "     3.46912604e-17   2.62694997e-21   1.43170581e-13   5.80732539e-23\n",
      "     2.44848491e-22   2.92804546e-26]\n",
      "  [  2.54166416e-24   3.00309331e-13   4.89693872e-26   3.59336037e-22\n",
      "     8.36593743e-15   1.83120553e-21   9.08854006e-12   4.42615551e-18\n",
      "     1.35830127e-20   3.54416116e-26]\n",
      "  [  3.14801024e-14   6.04120820e-23   3.29815988e-27   1.35175775e-19\n",
      "     5.71618800e-17   3.58208814e-16   8.59944872e-28   1.36147975e-28\n",
      "     5.05187491e-26   6.80010838e-26]\n",
      "  [  2.46741816e-19   3.38215988e-11   6.98910732e-23   6.38461888e-22\n",
      "     1.92252005e-04   3.19521362e-08   6.30127075e-27   6.37539477e-22\n",
      "     1.63572261e-13   6.88004196e-11]\n",
      "  [  4.99882747e-18   3.21233929e-22   6.85757788e-22   1.59837689e-20\n",
      "     1.02882697e-05   1.89730636e-12   3.91155596e-17   9.70454292e-29\n",
      "     1.22502438e-04   1.81956469e-19]\n",
      "  [  8.88834382e-18   1.09169401e-18   1.67277156e-23   8.51738121e-20\n",
      "     9.80251988e-13   6.16834971e-15   7.25554870e-19   6.34509838e-27\n",
      "     8.09483202e-24   9.79732150e-05]]]\n",
      "y after reshape\n",
      "[[  9.26417769e-26   2.05329692e-16   2.39903227e-26   3.94581571e-15\n",
      "    3.09933780e-24   4.91776902e-09   1.43591724e-12   1.40477643e-29\n",
      "    8.99357254e-18   3.29109161e-20   3.21445351e-22   2.86364506e-19\n",
      "    1.47325467e-26   1.85563437e-17   6.01926695e-16   5.57802966e-27\n",
      "    5.59924605e-12   3.61781484e-28   3.93465604e-09   4.69659067e-28\n",
      "    1.11318773e-21   1.90949532e-23   8.80161186e-21   6.90318518e-19\n",
      "    1.13342903e-21   2.48140413e-22   3.76282358e-16   2.23531764e-07\n",
      "    4.85048144e-21   1.66553071e-23   5.87556566e-19   8.45412403e-21\n",
      "    1.84434935e-17   2.19787324e-10   1.63593275e-26   3.44050611e-17\n",
      "    1.98196734e-26   4.09930077e-22   1.01457409e-09   7.30536882e-13\n",
      "    9.78548460e-24   1.09230486e-25   7.89173357e-02   3.06424890e-18\n",
      "    1.09718896e-17   1.39300643e-25   1.68042293e-26   5.78663081e-30\n",
      "    2.09938027e-23   5.00454531e-24   9.71397507e-27   8.48282261e-25\n",
      "    1.38814259e-21   9.20616457e-01   6.47814251e-24   9.32258060e-24\n",
      "    2.30832192e-07   2.37303038e-19   7.60439351e-24   4.47625327e-11\n",
      "    5.90380508e-24   5.78027774e-19   3.23249665e-21   6.30626420e-16\n",
      "    3.68788693e-18   1.45985330e-23   2.66259833e-20   9.67775765e-25\n",
      "    1.14164747e-18   7.58215787e-24   9.05740275e-18   5.13716456e-23\n",
      "    3.60643892e-19   2.01964794e-20   3.21258347e-16   1.18428354e-25\n",
      "    4.31002728e-27   1.03275801e-25   1.85670580e-25   8.68398671e-28\n",
      "    5.84173801e-18   4.92640193e-28   1.57479053e-14   1.60457994e-17\n",
      "    1.59554940e-17   3.26502376e-20   3.05984379e-19   8.33968866e-17\n",
      "    8.86146123e-24   4.60874557e-31   2.85231079e-19   4.34912670e-15\n",
      "    6.01911335e-09   3.40310263e-18   5.68546292e-16   3.47468795e-20\n",
      "    1.74932980e-22   8.12810362e-22   1.15703631e-23   4.92456601e-18\n",
      "    8.10167396e-22   3.33279700e-28   6.22699310e-19   1.23544605e-27\n",
      "    1.70909687e-22   4.80830022e-20   3.60792538e-27   4.84642154e-28\n",
      "    8.59526448e-25   1.13723410e-22   3.15776403e-12   5.21748927e-21\n",
      "    1.48625041e-31   3.33782502e-12   2.23323327e-24   5.34080318e-27\n",
      "    1.79881193e-15   9.84902299e-25   1.12261313e-23   1.70091088e-17\n",
      "    2.27768841e-10   3.43324204e-20   6.92353392e-23   9.55874744e-25\n",
      "    1.12200195e-16   4.71925374e-28   1.71919806e-11   1.23439631e-13\n",
      "    5.90068453e-21   5.43983022e-30   1.94794546e-17   7.06970667e-25\n",
      "    3.80441381e-09   2.22681188e-24   2.21407697e-10   3.86693061e-25\n",
      "    1.14313769e-29   6.39909235e-20   4.05957671e-25   6.93951719e-18\n",
      "    8.21022277e-28   2.54709315e-18   5.14182739e-22   1.24061096e-16\n",
      "    2.81530878e-24   4.88160407e-21   7.61477829e-18   2.33148838e-17\n",
      "    1.91305748e-24   2.04332899e-17   9.38584587e-24   1.40331406e-15\n",
      "    2.98821409e-22   9.58705221e-20   1.77997370e-23   1.26978918e-13\n",
      "    7.57606724e-27   6.08400845e-21   4.01141060e-15   3.39565927e-17\n",
      "    2.58244596e-27   1.83781243e-15   1.92044289e-10   4.07334731e-13\n",
      "    3.06381605e-25   1.53932656e-24   1.07907505e-21   3.74468522e-22\n",
      "    2.80272236e-24   1.14054337e-18   4.71003626e-24   1.08545167e-14\n",
      "    7.50117483e-11   4.25140410e-23   3.85056500e-16   7.67851058e-12\n",
      "    2.28508024e-21   7.22741813e-19   1.79518957e-27   9.64190954e-17\n",
      "    1.80028407e-19   1.82742492e-14   9.27822785e-22   1.00458394e-25\n",
      "    5.17551272e-13   1.65184367e-10   7.36134598e-20   5.44237829e-24\n",
      "    2.03164190e-25   4.85149719e-20   6.93984295e-11   3.24022812e-15\n",
      "    3.85203407e-24   1.47513110e-21   4.36212903e-22   1.66623330e-27\n",
      "    7.79066742e-25   1.28702231e-25   3.63312004e-23   7.79049454e-25\n",
      "    3.32770462e-22   7.57430333e-23   2.59754769e-22   1.65098186e-23\n",
      "    8.93642976e-24   4.26544470e-05   4.09579313e-21   5.31127808e-21\n",
      "    1.76268418e-26   3.35156473e-20   3.04328000e-20   2.61821853e-23\n",
      "    5.56973086e-26   9.40304353e-27   5.86760781e-24   2.09222482e-22\n",
      "    1.97730767e-24   5.24622667e-25   1.27525590e-28   6.66245241e-16\n",
      "    4.00237667e-16   2.05557946e-21   2.35238245e-21   1.50423682e-26\n",
      "    7.19640671e-24   1.60161001e-24   2.78001319e-21   4.31418262e-22\n",
      "    1.44982818e-27   4.48274565e-21   1.05571285e-16   1.40913089e-19\n",
      "    1.12766050e-28   1.39572284e-22   3.33341740e-16   6.78032134e-19\n",
      "    2.43467446e-28   7.80754740e-18   1.74596203e-22   6.06760721e-33\n",
      "    2.91742774e-08   6.39485244e-25   2.18212319e-23   1.09246873e-25\n",
      "    3.46912604e-17   2.62694997e-21   1.43170581e-13   5.80732539e-23\n",
      "    2.44848491e-22   2.92804546e-26   2.54166416e-24   3.00309331e-13\n",
      "    4.89693872e-26   3.59336037e-22   8.36593743e-15   1.83120553e-21\n",
      "    9.08854006e-12   4.42615551e-18   1.35830127e-20   3.54416116e-26\n",
      "    3.14801024e-14   6.04120820e-23   3.29815988e-27   1.35175775e-19\n",
      "    5.71618800e-17   3.58208814e-16   8.59944872e-28   1.36147975e-28\n",
      "    5.05187491e-26   6.80010838e-26   2.46741816e-19   3.38215988e-11\n",
      "    6.98910732e-23   6.38461888e-22   1.92252005e-04   3.19521362e-08\n",
      "    6.30127075e-27   6.37539477e-22   1.63572261e-13   6.88004196e-11\n",
      "    4.99882747e-18   3.21233929e-22   6.85757788e-22   1.59837689e-20\n",
      "    1.02882697e-05   1.89730636e-12   3.91155596e-17   9.70454292e-29\n",
      "    1.22502438e-04   1.81956469e-19   8.88834382e-18   1.09169401e-18\n",
      "    1.67277156e-23   8.51738121e-20   9.80251988e-13   6.16834971e-15\n",
      "    7.25554870e-19   6.34509838e-27   8.09483202e-24   9.79732150e-05]]\n"
     ]
    }
   ],
   "source": [
    "a = sampl( np.random.rand(M*N), 0.1 )\n",
    "# b = sampl( np.random.rand(M*N)*100, 0.1 )\n",
    "# c = sampl( np.zeros((1,M*N)), 0.1 )\n",
    "\n",
    "# b = np.reshape(b, (N,M))\n",
    "# b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12 into shape (300)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-ba92807c2914>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrand_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrand_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msampl_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbli\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msampl_img\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampl_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    230\u001b[0m            [5, 6]])\n\u001b[0;32m    231\u001b[0m     \"\"\"\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 12 into shape (300)"
     ]
    }
   ],
   "source": [
    "# code, x_hat_test = encoder([x_test[:1]])\n",
    "rand_code = np.eye(M)[np.random.choice(M, N)]\n",
    "rand_img = generator.predict(np.reshape(rand_code, [-1,N*M]))\n",
    "sampl_code = bli\n",
    "sampl_img =  generator.predict(np.reshape(sampl_code, [-1,N*M]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampl_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-503ac88e03c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# img_reshaped = rand_img.reshape(28,28)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg_reshaped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampl_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg_reshaped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sampl_img' is not defined"
     ]
    }
   ],
   "source": [
    "# img_reshaped = rand_img.reshape(28,28)\n",
    "img_reshaped = sampl_img.reshape(28,28)\n",
    "img_reshaped.shape\n",
    "plt.imshow(img_reshaped, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
